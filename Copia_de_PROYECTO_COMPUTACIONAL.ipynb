{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7_QcDpnUhj2"
      },
      "source": [
        "# **Entrenamiento de YoloV9**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeFO3PQEUp15"
      },
      "source": [
        "## **Instalación de las Librerias**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "96w_zstER8HK",
        "outputId": "de35897b-177b-4f03-c152-d262204c66e0"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuwAscefU1SF"
      },
      "source": [
        "## **Importación de las Librerias**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-bjgqn4VPxK",
        "outputId": "c995f810-dfb5-4ee2-a4de-72d4ca172888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.179 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 43.1/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "content= os.getcwd()\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image\n",
        "from roboflow import Roboflow\n",
        "HOME = \"/content\"\n",
        "!mkdir -p {HOME}/datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2qkCclUU77E"
      },
      "source": [
        "## **Descargar el dataset de Roboflow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRPhxIjsWyCK",
        "outputId": "d3e26067-4096-4797-becd-f88ea5a897f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "## Descargar DATASET\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"LYP9jcRo7cBAEBhJIiA8\")\n",
        "project = rf.workspace(\"sdpfoka\").project(\"my-first-project-suoa8\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov9\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHE6_MLXVITh"
      },
      "source": [
        "## **Entrenar el modelo de Yolo con el dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meTyJOtfXihZ"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=train model=yolov9s.pt data={dataset.location}/data.yaml epochs=125 imgsz=640 plots=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nzkts7_Ud0K"
      },
      "source": [
        "## **Verificar descarga**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_J2_9KEX1kA",
        "outputId": "abfb1d08-ba81-4502-a4a6-6f6fed285ca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best.pt  last.pt\n",
            "-rw-r--r-- 1 root root 15239874 Aug 14 04:57 runs/detect/train/weights/best.pt\n"
          ]
        }
      ],
      "source": [
        "##Guardar en una variable la carpeta del entrenamiento\n",
        "!ls runs/detect/train/weights/\n",
        "model_path = \"runs/detect/train/weights/best.pt\"\n",
        "!ls -l {model_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0XD26NXVUwq"
      },
      "source": [
        "## **Elegir la imagen a predecir**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "collapsed": true,
        "id": "Q52MNA-2DMQV",
        "outputId": "ebd46fff-ee24-4722-f50d-553746b3301d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7ee126f0-d5fd-42b5-9f74-dd3bb5961464\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7ee126f0-d5fd-42b5-9f74-dd3bb5961464\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving img028.jpeg to img028.jpeg\n"
          ]
        }
      ],
      "source": [
        "# Realizar predicciones basada en el entrenamiento, imagen completa\n",
        "import google.colab.files\n",
        "\n",
        "# Upload an image from your local machine\n",
        "uploaded = google.colab.files.upload()\n",
        "\n",
        "# Get the path of the uploaded image\n",
        "image_name = list(uploaded.keys())[0]\n",
        "image_path = f\"/content/{image_name}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pPGlYmTVfyT"
      },
      "source": [
        "## **Realizar la predicción**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMysHSW8jCyl"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=predict model={model_path} conf=0.25 source={image_path} save_crop=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRfPe_FAVnBs"
      },
      "source": [
        "## **Realizar la predicción con todas la imagenes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CTnimSj9AHA"
      },
      "outputs": [],
      "source": [
        "test = \"/content/test_images\"\n",
        "!yolo task=detect mode=predict model={model_path} conf=0.25 source={test} save_crop=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHCHkIn6VsHP"
      },
      "source": [
        "## **Realizar predicción para una sola clase**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RExAymbuGSZX"
      },
      "outputs": [],
      "source": [
        "# Ejecuta la predicción en la carpeta de imágenes de prueba, mostrando solo la clase 'Stem' (índice 1)\n",
        "!yolo task=detect mode=predict model={model_path} conf=0.25 source={image_path} classes=[2] show_labels=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Zc1pyjV55_"
      },
      "source": [
        "## **Mostrar imagenes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1dszzxGS7Uf"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='runs/detect/predict4/img028.jpg', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCu5mM5gS9hv"
      },
      "outputs": [],
      "source": [
        "Image(filename='runs/detect/predict3/crops/Stem/img00113.jpg', width=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXEFaVauV_GL"
      },
      "source": [
        "# **Analizar afectación del hongo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIf5pUt0WFT5"
      },
      "outputs": [],
      "source": [
        "import google.colab.files\n",
        "!mkdir crops_frijol\n",
        "!mkdir crops_frijol/healty_leaves\n",
        "!mkdir crops_frijol/Stem\n",
        "!mkdir crops_frijol/rooten_leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOsDEIidWH7e"
      },
      "outputs": [],
      "source": [
        "uploaded = google.colab.files.upload()\n",
        "\n",
        "image_name = list(uploaded.keys())[0]\n",
        "image_path = f\"/content/crops_frijol/{image_name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q9h_-cqWNrK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow # Para mostrar imágenes en Colab\n",
        "\n",
        "def analizar_afectacion_hoja(ruta_imagen):\n",
        "    \"\"\"\n",
        "    Analiza una imagen recortada de una hoja de frijol para determinar el\n",
        "    porcentaje de tejido sano, afectado y severamente afectado.\n",
        "\n",
        "    Args:\n",
        "        ruta_imagen (str): La ruta al archivo de imagen del recorte.\n",
        "\n",
        "    Returns:\n",
        "        dict: Un diccionario con los porcentajes de cada categoría.\n",
        "    \"\"\"\n",
        "    # 1. Cargar la imagen\n",
        "    img = cv2.imread(ruta_imagen)\n",
        "    if img is None:\n",
        "        print(f\"Error: No se pudo cargar la imagen en {ruta_imagen}\")\n",
        "        return None\n",
        "\n",
        "    # 2. Convertir la imagen al espacio de color HSV\n",
        "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # 3. Definir los rangos de color para cada estado en HSV\n",
        "    # Estos valores pueden necesitar ajustes finos según la iluminación y el tipo de cámara.\n",
        "    # Formato: (H_min, S_min, V_min), (H_max, S_max, V_max)\n",
        "\n",
        "    # Verde (Sano)\n",
        "    # Rango de tonos verdes\n",
        "    verde_bajo = np.array([35, 40, 40])\n",
        "    verde_alto = np.array([85, 255, 255])\n",
        "\n",
        "    # Amarillo (Afectado)\n",
        "    # Rango de tonos amarillos\n",
        "    amarillo_bajo = np.array([20, 100, 100])\n",
        "    amarillo_alto = np.array([30, 255, 255])\n",
        "\n",
        "    # Marrón/Negro (Quemado/Marchito - Severamente Afectado)\n",
        "    # Este rango es más complejo y puede incluir marrones oscuros y casi negros.\n",
        "    marron_bajo = np.array([10, 50, 20])\n",
        "    marron_alto = np.array([20, 255, 200])\n",
        "\n",
        "    # Podríamos añadir un segundo rango para los tonos más oscuros/quemados si es necesario.\n",
        "\n",
        "\n",
        "    # 4. Crear máscaras para cada rango de color\n",
        "    mascara_sana = cv2.inRange(hsv_img, verde_bajo, verde_alto)\n",
        "    mascara_afectada = cv2.inRange(hsv_img, amarillo_bajo, amarillo_alto)\n",
        "    mascara_severa = cv2.inRange(hsv_img, marron_bajo, marron_alto)\n",
        "\n",
        "    # 5. Calcular el área de cada máscara (contando los píxeles blancos)\n",
        "    pixeles_sanos = cv2.countNonZero(mascara_sana)\n",
        "    pixeles_afectados = cv2.countNonZero(mascara_afectada)\n",
        "    pixeles_severos = cv2.countNonZero(mascara_severa)\n",
        "\n",
        "    # Área total de la hoja analizada (suma de todos los píxeles clasificados)\n",
        "    # Se excluyen los píxeles del fondo que no caen en ninguna categoría.\n",
        "    total_pixeles_hoja = pixeles_sanos + pixeles_afectados + pixeles_severos\n",
        "\n",
        "    if total_pixeles_hoja == 0:\n",
        "      print(f\"Advertencia: No se detectó tejido de planta en {ruta_imagen}\")\n",
        "      return {'sano': 0, 'afectado': 0, 'severo': 0, 'afectacion_total': 0}\n",
        "\n",
        "\n",
        "    # 6. Calcular los porcentajes\n",
        "    porcentaje_sano = (pixeles_sanos / total_pixeles_hoja) * 100\n",
        "    porcentaje_afectado = (pixeles_afectados / total_pixeles_hoja) * 100\n",
        "    porcentaje_severo = (pixeles_severos / total_pixeles_hoja) * 100\n",
        "\n",
        "    # El porcentaje de afectación total es la suma de lo afectado y lo severo.\n",
        "    porcentaje_afectacion_total = porcentaje_afectado + porcentaje_severo\n",
        "\n",
        "    # 7. Crear la máscara superpuesta\n",
        "    mascara_superpuesta = np.zeros_like(img) # Inicializar con negro\n",
        "\n",
        "    # Asignar colores a las áreas clasificadas\n",
        "    mascara_superpuesta[mascara_sana > 0] = [0, 255, 0]  # Verde para sano (BGR)\n",
        "    mascara_superpuesta[mascara_afectada > 0] = [0, 255, 255] # Amarillo para afectado (BGR)\n",
        "    mascara_superpuesta[mascara_severa > 0] = [0, 0, 128] # Marrón oscuro para severo (BGR)\n",
        "\n",
        "\n",
        "    # # Opcional: Visualizar las máscaras para depuración\n",
        "    print(\"Imagen Original:\")\n",
        "    cv2_imshow(img)\n",
        "    print(\"Máscara Sana (Verde):\")\n",
        "    cv2_imshow(mascara_sana)\n",
        "    print(\"Máscara Afectada (Amarillo):\")\n",
        "    cv2_imshow(mascara_afectada)\n",
        "    print(\"Máscara Severa (Marrón):\")\n",
        "    cv2_imshow(mascara_severa)\n",
        "    print(\"Máscara Superpuesta:\")\n",
        "    cv2_imshow(mascara_superpuesta)\n",
        "\n",
        "\n",
        "    return {\n",
        "        'sano': porcentaje_sano,\n",
        "        'afectado': porcentaje_afectado,\n",
        "        'severo': porcentaje_severo,\n",
        "        'afectacion_total': porcentaje_afectacion_total\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbcH6xhvWSam"
      },
      "outputs": [],
      "source": [
        "# --- EJEMPLO DE USO ---\n",
        "\n",
        "# 1. Asegúrate de que tus imágenes recortadas están organizadas en subcarpetas\n",
        "#    dentro de \"crops_frijol\", como:\n",
        "#    crops_frijol/healty_leaves/imgXXX...\n",
        "#    crops_frijol/rooten_leaf/imgXXX...\n",
        "#    crops_frijol/Root/imgXXX...\n",
        "#    crops_frijol/Stem/imgXXX...\n",
        "\n",
        "# 2. Procesa todas las imágenes en las subcarpetas\n",
        "ruta_carpeta_crops = 'crops_frijol'\n",
        "resultados_por_imagen_y_categoria = {} # Diccionario para almacenar resultados agrupados por imagen original y categoría\n",
        "\n",
        "# Comprueba si la carpeta principal existe\n",
        "if os.path.exists(ruta_carpeta_crops):\n",
        "    # Iterar a través de los elementos dentro de la carpeta principal\n",
        "    for categoria in os.listdir(ruta_carpeta_crops):\n",
        "        ruta_categoria = os.path.join(ruta_carpeta_crops, categoria)\n",
        "\n",
        "        # Asegurarse de que es un directorio\n",
        "        if os.path.isdir(ruta_categoria):\n",
        "            print(f\"\\n### Procesando categoría: {categoria} ###\")\n",
        "            lista_imagenes = os.listdir(ruta_categoria)\n",
        "\n",
        "            for nombre_imagen in lista_imagenes:\n",
        "                if nombre_imagen.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    ruta_completa = os.path.join(ruta_categoria, nombre_imagen)\n",
        "                    print(f\"Analizando: {ruta_completa}\")\n",
        "                    resultado = analizar_afectacion_hoja(ruta_completa)\n",
        "\n",
        "                    if resultado:\n",
        "                        # Extraer el número de la imagen original del nombre del archivo\n",
        "                        # Asumimos que el formato es imgXXX...\n",
        "                        try:\n",
        "                            numero_imagen = int(nombre_imagen[3:6]) # Obtiene los 3 dígitos después de 'img'\n",
        "                        except ValueError:\n",
        "                            print(f\"Advertencia: Nombre de archivo inesperado '{nombre_imagen}'. No se pudo extraer el número de imagen.\")\n",
        "                            continue # Saltar esta imagen si el nombre no coincide con el formato esperado\n",
        "\n",
        "                        # Agregar el resultado al grupo de la imagen original y categoría\n",
        "                        if numero_imagen not in resultados_por_imagen_y_categoria:\n",
        "                            resultados_por_imagen_y_categoria[numero_imagen] = {}\n",
        "\n",
        "                        if categoria not in resultados_por_imagen_y_categoria[numero_imagen]:\n",
        "                            resultados_por_imagen_y_categoria[numero_imagen][categoria] = []\n",
        "\n",
        "                        resultados_por_imagen_y_categoria[numero_imagen][categoria].append(resultado) # Almacenar el diccionario completo de resultados\n",
        "\n",
        "                        print(f\"  -> Resultados para este recorte: Sano={resultado['sano']:.2f}%, Afectado={resultado['afectado']:.2f}%, Severo={resultado['severo']:.2f}%\")\n",
        "                        print(\"-----------------------------------------\")\n",
        "\n",
        "else:\n",
        "    print(f\"Error: La carpeta '{ruta_carpeta_crops}' no fue encontrada.\")\n",
        "    print(\"Por favor, crea la carpeta principal y las subcarpetas con tus imágenes recortadas.\")\n",
        "\n",
        "\n",
        "# 3. Calcular y mostrar el promedio de afectación y sano por cada imagen original y categoría\n",
        "if resultados_por_imagen_y_categoria:\n",
        "    print(f\"\\n#################################################\")\n",
        "    print(f\"ANÁLISIS RESUMIDO POR IMAGEN ORIGINAL Y CATEGORÍA\")\n",
        "    # Ordenar por número de imagen para una mejor presentación\n",
        "    for num_imagen in sorted(resultados_por_imagen_y_categoria.keys()):\n",
        "        print(f\"\\n--- Imagen {num_imagen:03d} ---\")\n",
        "        for categoria, resultados_recortes in resultados_por_imagen_y_categoria[num_imagen].items():\n",
        "            if resultados_recortes:\n",
        "                # Calcular promedios para esta categoría y esta imagen\n",
        "                promedio_sano = np.mean([res['sano'] for res in resultados_recortes])\n",
        "                promedio_afectado = np.mean([res['afectado'] for res in resultados_recortes])\n",
        "                # Incluimos severo en el total afectado para este resumen, si es relevante, o lo mostramos separado\n",
        "                # Decidimos mostrar Sano y el Afectación Total (Afectado + Severo)\n",
        "                promedio_afectacion_total = np.mean([res['afectacion_total'] for res in resultados_recortes])\n",
        "\n",
        "\n",
        "                print(f\"  Categoría '{categoria}': Sano = {promedio_sano:.2f}% | Afectación Total = {promedio_afectacion_total:.2f}%\")\n",
        "            else:\n",
        "                 print(f\"  Categoría '{categoria}': No se encontraron recortes válidos para la imagen {num_imagen:03d}.\")\n",
        "\n",
        "    print(f\"\\n#################################################\")\n",
        "else:\n",
        "    print(\"\\nNo se analizaron imágenes en las subcarpetas. El cálculo de promedios no es posible.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a8b491e"
      },
      "source": [
        "# **Descargar proyecto**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "8b116e9f",
        "outputId": "76322005-2c28-41eb-c6da-c2a9ade36145"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Zip the /content directory\n",
        "!zip -r /content.zip /content/\n",
        "\n",
        "# Download the zip file\n",
        "files.download('/content.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65d3f102",
        "outputId": "2c31a71a-14f1-4acd-c29c-14e0ef9a52df"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = '/content/content.zip'\n",
        "extract_dir = '/'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"'{zip_file_path}' unzipped to '{extract_dir}'\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
